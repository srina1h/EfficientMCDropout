{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Specific package requirement"
      ],
      "metadata": {
        "id": "Li7Hoh1rp16z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uO95JeJkFhBE"
      },
      "outputs": [],
      "source": [
        "pip install datasets transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "BkPQSLrSp9RJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l12uxouFiK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e083e1d3-dc55-443a-803c-2ae5e6b324ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-04-11 14:58:45.949989: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-11 14:58:46.008075: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-04-11 14:58:46.271691: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2024-04-11 14:58:46.271719: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2024-04-11 14:58:46.271721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset,Dataset,DatasetDict\n",
        "from transformers import DataCollatorWithPadding,AutoModelForSequenceClassification, Trainer, TrainingArguments,AutoTokenizer,AutoModel,AutoConfig\n",
        "from transformers.modeling_outputs import TokenClassifierOutput\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from datasets import load_metric\n",
        "from tqdm.auto import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW,get_scheduler\n",
        "import numpy as np\n",
        "from statistics import NormalDist\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load datasets & tokenize, pre-trained model checkpoint"
      ],
      "metadata": {
        "id": "wTtAx-udqCyM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDTUyBdyF9Jv",
        "outputId": "fce9048c-266b-4173-8d2a-401c317f5c2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['headline', 'label'],\n",
              "        num_rows: 22802\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['headline', 'label'],\n",
              "        num_rows: 2851\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['headline', 'label'],\n",
              "        num_rows: 2850\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "data=load_dataset(\"json\",data_files=\"/home/ssrini27/random/Sarcasm_Headlines_Dataset_v2.json\")\n",
        "data=data.rename_column(\"is_sarcastic\",\"label\")\n",
        "\n",
        "data=data.remove_columns(['article_link'])\n",
        "\n",
        "data.set_format('pandas')\n",
        "data=data['train'][:]\n",
        "\n",
        "data.drop_duplicates(subset=['headline'],inplace=True)\n",
        "data=data.reset_index()[['headline','label']]\n",
        "data=Dataset.from_pandas(data)\n",
        "\n",
        "# 80% train, 20% test + validation\n",
        "train_testvalid = data.train_test_split(test_size=0.2,seed=15)\n",
        "\n",
        "# Split the 10% test + valid in half test, half valid\n",
        "test_valid = train_testvalid['test'].train_test_split(test_size=0.5,seed=15)\n",
        "\n",
        "# gather everyone if you want to have a single DatasetDict\n",
        "data = DatasetDict({\n",
        "    'train': train_testvalid['train'],\n",
        "    'test': test_valid['test'],\n",
        "    'valid': test_valid['train']})\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liKtNCQt1Gr2"
      },
      "outputs": [],
      "source": [
        "checkpoint = \"cardiffnlp/twitter-roberta-base-emotion\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "tokenizer.model_max_len=512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "3899706fec384172bfd3de5b6a1eafb7",
            "f9c44283b49f4db696ffaa8d3fe3768b",
            "5df55ec6b366442188a9c731450fba0d",
            "104671c5be1840878d21bff49dd7cddb",
            "591a870bec484fe28f906f6c11e18a86",
            "f48090dcf81b4f0a99f8416bc697efb0",
            "4afc0ebce77540829f9b7ba895a8fa5b",
            "2a967766a92d4ccca11055cf4a459f20",
            "565ebf94595c4547b7a5cd532baf9fdb",
            "985fe03f110849edb7262f11dfe2abb5",
            "00b592e82c3640f592bdd627f60c1120",
            "b9cbc1664cba49f89d1ab29dd2627f8a",
            "3467c2b955484c00aecd458959632da0",
            "75d04974fe9441afa4153187b56d7011",
            "c8ad5b657f854bb188bf41d354debeb0",
            "39139856907e4cd28fdcdf9d019da4bb",
            "ca66b23f019047c392ec072b76d610d7",
            "9cb6513764c748a587eac3802706b637",
            "a2eb97573d5a4f4fa59c78c01873539e",
            "25e1f0a103a8421c8de794fe310a3075",
            "ae8a803f26bb4bff8211b1092f156d8f",
            "193eb30f609d4320affaf41b261434ef",
            "4d54259a098743f8a8a8011edecc4c83",
            "18b44428e6a649b2ae739c647f07085c",
            "d88d5401e7b2461c956eb36315c553ff",
            "12878312617d40d2ba0a106c5836629a",
            "a1dd87de3feb4bebbcb31091916e7da3",
            "a695f55cf48142ed85ed430ca53b3b7e",
            "898206a2027a409396007fe583d33e86",
            "6f3ce4b4aa4a48c4a0b79a7ec619dea8",
            "39ddc2f873624931b08cfb5a54cc679f",
            "3a2547b7ca9b48ccb9b456d8384a847c",
            "9772db6177ad49debc405fae9b8f2b40"
          ]
        },
        "id": "zmvmtL9f1qI1",
        "outputId": "0b8c01a7-5418-454c-8719-454ed045fa9d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/22802 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3899706fec384172bfd3de5b6a1eafb7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2851 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9cbc1664cba49f89d1ab29dd2627f8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2850 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d54259a098743f8a8a8011edecc4c83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['headline', 'label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 22802\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['headline', 'label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 2851\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['headline', 'label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 2850\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "def tokenize(batch):\n",
        "  return tokenizer(batch[\"headline\"], truncation=True,max_length=512)\n",
        "\n",
        "tokenized_dataset = data.map(tokenize, batched=True)\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gifq7QdY1uz1"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset.set_format(\"torch\",columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define our WHOLE model"
      ],
      "metadata": {
        "id": "UbE62tidqL3-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mMzQ2T8JBov"
      },
      "outputs": [],
      "source": [
        "class CustomModel(nn.Module):\n",
        "  def __init__(self,checkpoint,num_labels):\n",
        "    super(CustomModel,self).__init__()\n",
        "    self.num_labels = num_labels\n",
        "\n",
        "    #Load Model with given checkpoint and extract its body\n",
        "    self.model = model = AutoModel.from_pretrained(checkpoint,config=AutoConfig.from_pretrained(checkpoint, output_attentions=True,output_hidden_states=True))\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.classifier = nn.Linear(768,num_labels) # load and initialize weights\n",
        "\n",
        "  def forward(self, input_ids=None, attention_mask=None,labels=None):\n",
        "    #Extract outputs from the body\n",
        "    outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    #Add custom layers\n",
        "    sequence_output = self.dropout(outputs[0]) #outputs[0]=last hidden state\n",
        "\n",
        "    logits = self.classifier(sequence_output[:,0,:].view(-1,768))\n",
        "\n",
        "    loss = None\n",
        "    if labels is not None:\n",
        "      loss_fct = nn.CrossEntropyLoss()\n",
        "      loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "    return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states,attentions=outputs.attentions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with couple extra layers tested (Not considered)"
      ],
      "metadata": {
        "id": "zGUpyhLTGqTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(nn.Module):\n",
        "  def __init__(self,checkpoint,num_labels):\n",
        "    super(CustomModel,self).__init__()\n",
        "    self.num_labels = num_labels\n",
        "\n",
        "    #Load Model with given checkpoint and extract its body\n",
        "    self.model = model = AutoModel.from_pretrained(checkpoint,config=AutoConfig.from_pretrained(checkpoint, output_attentions=True,output_hidden_states=True))\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.linear1 = nn.Linear(768, 768)\n",
        "    self.dropout2 = nn.Dropout(0.2)\n",
        "    self.classifier = nn.Linear(768,num_labels) # load and initialize weights\n",
        "\n",
        "  def forward(self, input_ids=None, attention_mask=None,labels=None):\n",
        "    #Extract outputs from the body\n",
        "    outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    #Add custom layers\n",
        "    sequence_output = self.dropout(outputs[0]) #outputs[0]=last hidden state\n",
        "\n",
        "    sequence_output = self.linear1(sequence_output)  # Apply linear layer\n",
        "    sequence_output = self.dropout2(sequence_output)  # Apply dropout\n",
        "\n",
        "    logits = self.classifier(sequence_output[:,0,:].view(-1,768))\n",
        "\n",
        "    loss = None\n",
        "    if labels is not None:\n",
        "      loss_fct = nn.CrossEntropyLoss()\n",
        "      loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "    return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states,attentions=outputs.attentions)"
      ],
      "metadata": {
        "id": "6zzhJ5QRAxNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTyedPVt2J7H",
        "outputId": "73b2de9f-55fe-49f6-9aee-86ef96c2df2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-emotion and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model=CustomModel(checkpoint=checkpoint,num_labels=2).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Dataloaders"
      ],
      "metadata": {
        "id": "2VeoKAAiqQtQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGA8mRTcJ4Eh"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(\n",
        "    tokenized_dataset[\"train\"], shuffle=True, batch_size=32, collate_fn=data_collator\n",
        ")\n",
        "\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_dataset[\"valid\"], batch_size=32, collate_fn=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set training params"
      ],
      "metadata": {
        "id": "SVi3sr65qVt6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i13DJTTA2tYB",
        "outputId": "d3501913-3ac1-45ea-f94d-f194286a9540"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/ssrini27/virtualenv/pureDL3.9/lib/python3.9/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "num_epochs = 5\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "print(num_training_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ],
      "metadata": {
        "id": "ol4lsQEPqXf1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yFcd5Xu3BbJ"
      },
      "outputs": [],
      "source": [
        "metric = load_metric(\"f1\")\n",
        "\n",
        "progress_bar_train = tqdm(range(num_training_steps))\n",
        "progress_bar_eval = tqdm(range(num_epochs * len(eval_dataloader)))\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  for batch in train_dataloader:\n",
        "      batch = {k: v.to(device) for k, v in batch.items()}\n",
        "      outputs = model(**batch)\n",
        "      loss = outputs.loss\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "      lr_scheduler.step()\n",
        "      optimizer.zero_grad()\n",
        "      progress_bar_train.update(1)\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  for batch in eval_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "    progress_bar_eval.update(1)\n",
        "\n",
        "  print(metric.compute())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH6xss-S96ra",
        "outputId": "79a6fbb8-49fd-42d0-f34a-6afccd749ec3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'f1': 0.9276241000378932}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    tokenized_dataset[\"test\"], batch_size=32, collate_fn=data_collator\n",
        ")\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "metric.compute()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving and loading the model"
      ],
      "metadata": {
        "id": "KlsZcIBUqbLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/home/ssrini27/random/model_5.pt\")"
      ],
      "metadata": {
        "id": "DbJ6b6JEybLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomModel(checkpoint=checkpoint,num_labels=2)\n",
        "model.load_state_dict(torch.load(\"/home/ssrini27/random/model_5.pt\"))\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEkarhdsFn06",
        "outputId": "ea8d1762-7e9b-4af6-b66d-1ac44de559e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-emotion and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomModel(\n",
              "  (model): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining our custom SPLIT model"
      ],
      "metadata": {
        "id": "QdaZzQ7hqem1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel_body(nn.Module):\n",
        "  def __init__(self,checkpoint):\n",
        "    super(CustomModel_body,self).__init__()\n",
        "\n",
        "    #Load Model with given checkpoint and extract its body\n",
        "    self.model = AutoModel.from_pretrained(checkpoint,config=AutoConfig.from_pretrained(checkpoint, output_attentions=True,output_hidden_states=True))\n",
        "\n",
        "  def forward(self, input_ids=None, attention_mask=None):\n",
        "    #Extract outputs from the body\n",
        "    outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    return outputs[0], outputs.hidden_states, outputs.attentions\n",
        "\n",
        "class CustomModel_head(nn.Module):\n",
        "  def __init__(self,num_labels):\n",
        "    super(CustomModel_head,self).__init__()\n",
        "    self.num_labels = num_labels\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.classifier = nn.Linear(768,num_labels) # load and initialize weights\n",
        "\n",
        "  def forward(self, sequence_output, transformer_hidden_states, transformer_attentions, labels=None):\n",
        "    sequence_output = self.dropout(sequence_output)\n",
        "    logits = self.classifier(sequence_output[:,0,:].view(-1,768)) # calculate losses\n",
        "\n",
        "    loss = None\n",
        "    if labels is not None:\n",
        "      loss_fct = nn.CrossEntropyLoss()\n",
        "      loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "    return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=transformer_hidden_states, attentions=transformer_attentions)"
      ],
      "metadata": {
        "id": "z8AHBgTCuqHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load saved model into our split model classes"
      ],
      "metadata": {
        "id": "HzoRbVvVqiC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_body = CustomModel_body(checkpoint)\n",
        "model_head = CustomModel_head(num_labels=2)\n",
        "\n",
        "model_body.load_state_dict(model.state_dict(), strict=False)\n",
        "model_head.load_state_dict(model.state_dict(), strict = False)\n",
        "\n",
        "model_body.to(device)\n",
        "model_head.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBDc_PK8xtG_",
        "outputId": "8f7b5f38-9827-4ac1-a660-34cd0115d80b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-emotion and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomModel_head(\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform normal evaluation on the combied model to test"
      ],
      "metadata": {
        "id": "WyVs6OoGqoJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_body.eval()\n",
        "model_head.train()\n",
        "metric = load_metric(\"f1\")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    tokenized_dataset[\"test\"], batch_size=32, collate_fn=data_collator\n",
        ")\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        sequence_output, hidden_states, transformer_attentions = model_body(batch['input_ids'], batch['attention_mask'])\n",
        "        outputs = model_head(sequence_output, hidden_states, transformer_attentions, labels = batch['labels'])\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "metric.compute()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TZRciLix9BS",
        "outputId": "94a6f416-2e35-4fe0-d88d-ef999d1bf392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_684592/3399149219.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"f1\")\n",
            "/home/ssrini27/virtualenv/pureDL3.9/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'f1': 0.9284361984096933}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform MC evaluation on the SPLIT model"
      ],
      "metadata": {
        "id": "Ht-KdlGgrDXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_body.eval()\n",
        "model_head.train()\n",
        "metric = load_metric(\"f1\")\n",
        "\n",
        "no_MC_iterations = 100\n",
        "confidence_percent = 0.95\n",
        "z_value = NormalDist().inv_cdf((1 + confidence_percent) / 2.)\n",
        "threshold_value = 0.5\n",
        "\n",
        "# batch size 1 to perform UQ on single sample\n",
        "test_dataloader = DataLoader(\n",
        "    tokenized_dataset[\"test\"], batch_size=1, collate_fn=data_collator\n",
        ")\n",
        "\n",
        "considered_samples = []\n",
        "ignored_samples = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    # Only get body outputs for 1 itr\n",
        "    with torch.no_grad():\n",
        "        sequence_output, hidden_states, transformer_attentions = model_body(batch['input_ids'], batch['attention_mask'])\n",
        "\n",
        "    # Perform rest of the iterations ONLY on the head of the model\n",
        "    MC_outputs = np.zeros((no_MC_iterations, 2))\n",
        "\n",
        "    for i in range(no_MC_iterations):\n",
        "        with torch.no_grad():\n",
        "            outputs = model_head(sequence_output, hidden_states, transformer_attentions, labels = batch['labels'])\n",
        "        logits = outputs.logits\n",
        "\n",
        "        MC_outputs[i] = torch.sigmoid(logits)[0].numpy(force = True)\n",
        "\n",
        "        # predictions = torch.argmax(logits, dim=-1).to('cpu')\n",
        "        # metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "    mean_outputs = np.mean(MC_outputs, axis = 0)\n",
        "    std_outputs = np.std(MC_outputs, axis = 0)\n",
        "\n",
        "    ignored_sample_flag = False\n",
        "\n",
        "    for i in range(len(mean_outputs)):\n",
        "        interval_min = mean_outputs[i] - z_value*std_outputs[i]\n",
        "        interval_max = mean_outputs[i] + z_value*std_outputs[i]\n",
        "        if interval_max < threshold_value:\n",
        "            final_class_pred = 0\n",
        "        elif interval_min > threshold_value:\n",
        "            final_class_pred = 1\n",
        "        else:\n",
        "            ignored_sample_flag = True\n",
        "\n",
        "    if ignored_sample_flag:\n",
        "        ignored_samples.append([np.argmax(mean_outputs), batch['labels'].numpy(force = True)[0]])\n",
        "    else:\n",
        "        considered_samples.append([final_class_pred, batch['labels'].numpy(force = True)[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s8Zy60Jq38G",
        "outputId": "4f8d4294-276c-489a-d5ce-29999cc80f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/ssrini27/virtualenv/pureDL3.9/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "considered_samples = np.array(considered_samples)\n",
        "ignored_samples = np.array(ignored_samples)"
      ],
      "metadata": {
        "id": "Ei5Rc7-ZyOOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slightly higher F1 score among chosen samples"
      ],
      "metadata": {
        "id": "0-mzv8vhy7lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric(\"f1\")\n",
        "metric.add_batch(predictions=considered_samples[:, 0], references=considered_samples[:, 1])\n",
        "metric.compute()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9ZQiPPGtrhZ",
        "outputId": "e6815d8f-3815-41ee-9bc5-184576dc5d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/ssrini27/virtualenv/pureDL3.9/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'f1': 0.9392649903288202}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Low F1 score among other samples"
      ],
      "metadata": {
        "id": "HMqHYu0HzEjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric(\"f1\")\n",
        "metric.add_batch(predictions=ignored_samples[:, 0], references=ignored_samples[:, 1])\n",
        "metric.compute()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqUd1qXVt-q_",
        "outputId": "52126242-b652-4232-9f7c-14fa3f9f2f38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/ssrini27/virtualenv/pureDL3.9/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'f1': 0.45614035087719296}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ignored_samples.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G19w1di0zZLq",
        "outputId": "a2281f27-d188-42d7-bc7a-8e53be1c3412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric('accuracy')\n",
        "metric.add_batch(predictions=ignored_samples[:, 0], references=ignored_samples[:, 1])\n",
        "metric.compute()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cXK1uFJzUDC",
        "outputId": "c036a3ea-2dac-4b05-e549-fe5e6e671318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/ssrini27/virtualenv/pureDL3.9/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.3404255319148936}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation on WHOLE model on test dataset (not necessary)"
      ],
      "metadata": {
        "id": "d9mQw8fbqu6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "model.dropout.train()\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    tokenized_dataset[\"test\"], batch_size=1, collate_fn=data_collator\n",
        ")\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    print(\"one\" + str(logits))\n",
        "    with torch.no_grad():\n",
        "\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    print(\"two\" + str(logits))\n",
        "\n",
        "\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])"
      ],
      "metadata": {
        "id": "pkYNQh4irXw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Timing the models with and without splitting"
      ],
      "metadata": {
        "id": "pHrT3GhqBVRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(\n",
        "    tokenized_dataset[\"test\"], batch_size=1, collate_fn=data_collator\n",
        ")\n",
        "extracted_batch = 0\n",
        "for batch in test_dataloader:\n",
        "    extracted_batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    break\n",
        "\n",
        "model.eval()\n",
        "model.dropout.train()\n",
        "model_body.eval()\n",
        "model_head.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sVxpG8dCsI5",
        "outputId": "c9051d77-09bd-4bf8-88fc-c301cba0d4df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomModel_head(\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "with torch.no_grad():\n",
        "    outputs = model(**extracted_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe6Irn-nBU1q",
        "outputId": "0b34cd8c-46b3-49db-b25b-4c28c57188ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.91 ms Â± 1.68 Âµs per loop (mean Â± std. dev. of 7 runs, 1,000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "with torch.no_grad():\n",
        "    sequence_output, hidden_states, transformer_attentions = model_body(extracted_batch['input_ids'], extracted_batch['attention_mask'])\n",
        "    outputs = model_head(sequence_output, hidden_states, transformer_attentions, labels = extracted_batch['labels'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmFlK_jUCo5s",
        "outputId": "1404ce45-09da-46b7-a829-5112c84c9581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.94 ms Â± 1.47 Âµs per loop (mean Â± std. dev. of 7 runs, 1,000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wee see on avg splitting the model costs more over 1 iteration\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bg-iqnbWEQZr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying over 50 iterations"
      ],
      "metadata": {
        "id": "pBat_CYFEZ15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "for i in range(50):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**extracted_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VALU6f3tEYyb",
        "outputId": "6fe80857-09f0-4584-d013-eb0dfe663671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95.8 ms Â± 175 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "sequence_output, hidden_states, transformer_attentions = model_body(extracted_batch['input_ids'], extracted_batch['attention_mask'])\n",
        "for i in range(50):\n",
        "    with torch.no_grad():\n",
        "        outputs = model_head(sequence_output, hidden_states, transformer_attentions, labels = extracted_batch['labels'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLI0uLqAFGIw",
        "outputId": "ac4fc335-76d4-4b01-a0d7-fd94290cdc92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.78 ms Â± 8.83 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But running over 50 iterations, there is a speedup of 25"
      ],
      "metadata": {
        "id": "xVzKv8IqFr3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying 100 iterations"
      ],
      "metadata": {
        "id": "iI3zxK19Fw_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "for i in range(100):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**extracted_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYMrxagLFwJI",
        "outputId": "26f92075-8441-4334-c4fc-ab112bbbf761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "190 ms Â± 93.3 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "sequence_output, hidden_states, transformer_attentions = model_body(extracted_batch['input_ids'], extracted_batch['attention_mask'])\n",
        "for i in range(100):\n",
        "    with torch.no_grad():\n",
        "        outputs = model_head(sequence_output, hidden_states, transformer_attentions, labels = extracted_batch['labels'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFRlqVs0F0Hg",
        "outputId": "3c91ba6c-00a4-4c39-c4c6-7ddd1162546f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.61 ms Â± 10.3 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running over 100 iterations we have a 33 times speedup!"
      ],
      "metadata": {
        "id": "elnxyjwEGGEy"
      }
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3899706fec384172bfd3de5b6a1eafb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9c44283b49f4db696ffaa8d3fe3768b",
              "IPY_MODEL_5df55ec6b366442188a9c731450fba0d",
              "IPY_MODEL_104671c5be1840878d21bff49dd7cddb"
            ],
            "layout": "IPY_MODEL_591a870bec484fe28f906f6c11e18a86",
            "tabbable": null,
            "tooltip": null
          }
        },
        "f9c44283b49f4db696ffaa8d3fe3768b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_f48090dcf81b4f0a99f8416bc697efb0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4afc0ebce77540829f9b7ba895a8fa5b",
            "tabbable": null,
            "tooltip": null,
            "value": "Map:â€‡100%"
          }
        },
        "5df55ec6b366442188a9c731450fba0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_2a967766a92d4ccca11055cf4a459f20",
            "max": 22802,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_565ebf94595c4547b7a5cd532baf9fdb",
            "tabbable": null,
            "tooltip": null,
            "value": 22802
          }
        },
        "104671c5be1840878d21bff49dd7cddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_985fe03f110849edb7262f11dfe2abb5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_00b592e82c3640f592bdd627f60c1120",
            "tabbable": null,
            "tooltip": null,
            "value": "â€‡22802/22802â€‡[00:00&lt;00:00,â€‡69591.99â€‡examples/s]"
          }
        },
        "591a870bec484fe28f906f6c11e18a86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f48090dcf81b4f0a99f8416bc697efb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4afc0ebce77540829f9b7ba895a8fa5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "2a967766a92d4ccca11055cf4a459f20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "565ebf94595c4547b7a5cd532baf9fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "985fe03f110849edb7262f11dfe2abb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00b592e82c3640f592bdd627f60c1120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "b9cbc1664cba49f89d1ab29dd2627f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3467c2b955484c00aecd458959632da0",
              "IPY_MODEL_75d04974fe9441afa4153187b56d7011",
              "IPY_MODEL_c8ad5b657f854bb188bf41d354debeb0"
            ],
            "layout": "IPY_MODEL_39139856907e4cd28fdcdf9d019da4bb",
            "tabbable": null,
            "tooltip": null
          }
        },
        "3467c2b955484c00aecd458959632da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_ca66b23f019047c392ec072b76d610d7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9cb6513764c748a587eac3802706b637",
            "tabbable": null,
            "tooltip": null,
            "value": "Map:â€‡100%"
          }
        },
        "75d04974fe9441afa4153187b56d7011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_a2eb97573d5a4f4fa59c78c01873539e",
            "max": 2851,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25e1f0a103a8421c8de794fe310a3075",
            "tabbable": null,
            "tooltip": null,
            "value": 2851
          }
        },
        "c8ad5b657f854bb188bf41d354debeb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_ae8a803f26bb4bff8211b1092f156d8f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_193eb30f609d4320affaf41b261434ef",
            "tabbable": null,
            "tooltip": null,
            "value": "â€‡2851/2851â€‡[00:00&lt;00:00,â€‡84322.03â€‡examples/s]"
          }
        },
        "39139856907e4cd28fdcdf9d019da4bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca66b23f019047c392ec072b76d610d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cb6513764c748a587eac3802706b637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "a2eb97573d5a4f4fa59c78c01873539e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25e1f0a103a8421c8de794fe310a3075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae8a803f26bb4bff8211b1092f156d8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "193eb30f609d4320affaf41b261434ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "4d54259a098743f8a8a8011edecc4c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18b44428e6a649b2ae739c647f07085c",
              "IPY_MODEL_d88d5401e7b2461c956eb36315c553ff",
              "IPY_MODEL_12878312617d40d2ba0a106c5836629a"
            ],
            "layout": "IPY_MODEL_a1dd87de3feb4bebbcb31091916e7da3",
            "tabbable": null,
            "tooltip": null
          }
        },
        "18b44428e6a649b2ae739c647f07085c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_a695f55cf48142ed85ed430ca53b3b7e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_898206a2027a409396007fe583d33e86",
            "tabbable": null,
            "tooltip": null,
            "value": "Map:â€‡100%"
          }
        },
        "d88d5401e7b2461c956eb36315c553ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_6f3ce4b4aa4a48c4a0b79a7ec619dea8",
            "max": 2850,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39ddc2f873624931b08cfb5a54cc679f",
            "tabbable": null,
            "tooltip": null,
            "value": 2850
          }
        },
        "12878312617d40d2ba0a106c5836629a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_3a2547b7ca9b48ccb9b456d8384a847c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9772db6177ad49debc405fae9b8f2b40",
            "tabbable": null,
            "tooltip": null,
            "value": "â€‡2850/2850â€‡[00:00&lt;00:00,â€‡89946.92â€‡examples/s]"
          }
        },
        "a1dd87de3feb4bebbcb31091916e7da3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a695f55cf48142ed85ed430ca53b3b7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "898206a2027a409396007fe583d33e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "6f3ce4b4aa4a48c4a0b79a7ec619dea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39ddc2f873624931b08cfb5a54cc679f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a2547b7ca9b48ccb9b456d8384a847c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9772db6177ad49debc405fae9b8f2b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    },
    "kernelspec": {
      "name": "myenv",
      "display_name": "myenv"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}